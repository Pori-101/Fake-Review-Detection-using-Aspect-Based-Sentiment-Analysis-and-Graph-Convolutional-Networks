{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Datasets/ottdata.csv') #Change Path to test code on other datasets\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pandas as pd\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def get_bert_embedding(text):\n",
    "    # Tokenize and encode the text\n",
    "    inputs = tokenizer(text, return_tensors='pt', max_length=512, truncation=True, padding='max_length')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # Extract the embeddings from the model output\n",
    "    embeddings = outputs.last_hidden_state\n",
    "    # Compute the mean of the embeddings for all tokens\n",
    "    mean_embeddings = embeddings.mean(dim=1)\n",
    "    return mean_embeddings.squeeze().numpy()\n",
    "\n",
    "# Compute BERT embeddings for each review\n",
    "df['bert_embedding'] = df['review'].apply(get_bert_embedding)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['label']\n",
    "\n",
    "if len(labels) != bert_embeddings.shape[0]:\n",
    "    raise ValueError(\"Mismatch between number of labels and number of embeddings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    bert_embeddings, labels, test_size=0.2, random_state=42, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Initialize the classifier\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "print(\"Random Forest - Cross-validation scores:\", scores)\n",
    "print(\"Random Forest - Mean CV score:\", np.mean(scores))\n",
    "\n",
    "# Train the classifier on the full training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Random Forest - Test accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "svm_clf = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "svm_scores = cross_val_score(svm_clf, X_train, y_train, cv=5)\n",
    "print(\"SVM - Cross-validation scores:\", svm_scores)\n",
    "print(\"SVM - Mean CV score:\", np.mean(svm_scores))\n",
    "\n",
    "# Train the classifier on the full training data\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = svm_clf.predict(X_test)\n",
    "print(\"SVM - Test accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the Logistic Regression classifier\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "log_reg_scores = cross_val_score(log_reg, X_train, y_train, cv=5)\n",
    "print(\"Logistic Regression - Cross-validation scores:\", log_reg_scores)\n",
    "print(\"Logistic Regression - Mean CV score:\", np.mean(log_reg_scores))\n",
    "\n",
    "# Train the classifier on the full training data\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "print(\"Logistic Regression - Test accuracy:\", accuracy_score(y_test, y_pred_log_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Initialize the Naive Bayes classifier\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "nb_scores = cross_val_score(nb_classifier, X_train, y_train, cv=5)\n",
    "print(\"Naive Bayes - Cross-validation scores:\", nb_scores)\n",
    "print(\"Naive Bayes - Mean CV score:\", np.mean(nb_scores))\n",
    "\n",
    "# Train the classifier on the full training data\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred_nb = nb_classifier.predict(X_test)\n",
    "print(\"Naive Bayes - Test accuracy:\", accuracy_score(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Initialize the MLP Classifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(256, 128), activation='relu', solver='adam', \n",
    "                    max_iter=500, random_state=42)\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "mlp_scores = cross_val_score(mlp, X_train, y_train, cv=5)\n",
    "print(\"MLP - Cross-validation scores:\", mlp_scores)\n",
    "print(\"MLP - Mean CV score:\", np.mean(mlp_scores))\n",
    "\n",
    "# Train the classifier on the full training data\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred_mlp = mlp.predict(X_test)\n",
    "print(\"MLP - Test accuracy:\", accuracy_score(y_test, y_pred_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the MLP Classifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(256, 128), activation='relu', solver='adam', \n",
    "                    max_iter=500, random_state=42)\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "mlp_scores = cross_val_score(mlp, X_train, y_train, cv=5)\n",
    "print(\"MLP - Cross-validation scores:\", mlp_scores)\n",
    "print(\"MLP - Mean CV score:\", np.mean(mlp_scores))\n",
    "\n",
    "# Train the classifier on the full training data\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred_mlp = mlp.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_mlp)\n",
    "precision = precision_score(y_test, y_pred_mlp)\n",
    "recall = recall_score(y_test, y_pred_mlp)\n",
    "f1 = f1_score(y_test, y_pred_mlp)\n",
    "# Calculate AUC\n",
    "# Ensure y_test and y_pred for AUC calculation are appropriate (e.g., binary classification output)\n",
    "# If y_pred needs to be probability scores, use predict_proba and get the probabilities for the positive class\n",
    "y_scores_mlp = mlp.predict_proba(X_test)[:, 1] \n",
    "auc = roc_auc_score(y_test, y_scores_mlp)\n",
    "\n",
    "print(\"MLP - Test accuracy:\", accuracy)\n",
    "print(\"MLP - Precision:\", precision)\n",
    "print(\"MLP - Recall:\", recall)\n",
    "print(\"MLP - F1 Score:\", f1)\n",
    "print(\"MLP - AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glove Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Glove Embeddings\n",
    "def load_glove_embeddings(path):\n",
    "    embeddings_index = {}\n",
    "    with open(path, 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    return embeddings_index\n",
    "\n",
    "glove_embeddings = load_glove_embeddings('glove.6B.300d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    # Simple preprocessing: convert to lowercase and split into words\n",
    "    return text.lower().split()\n",
    "\n",
    "def get_embedding(text, embeddings):\n",
    "    words = preprocess(text)\n",
    "    # Obtain embeddings for each word and ignore words not in the embeddings\n",
    "    word_embeddings = [embeddings[word] for word in words if word in embeddings]\n",
    "    \n",
    "    # Handle case with no valid words found in the embeddings\n",
    "    if not word_embeddings:\n",
    "        return np.zeros(300)  \n",
    "    \n",
    "    # Compute the average of the embeddings\n",
    "    return np.mean(word_embeddings, axis=0)\n",
    "\n",
    "df['embedding'] = df['review'].apply(lambda x: get_embedding(x, glove_embeddings))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['label']\n",
    "\n",
    "if len(labels) != df['embedding'].shape[0]:\n",
    "    raise ValueError(\"Mismatch between number of labels and number of embeddings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_matrix = np.stack(df['embedding'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    embeddings_matrix, labels, test_size=0.2, random_state=42, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Initialize the classifier\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "print(\"Random Forest - Cross-validation scores:\", scores)\n",
    "print(\"Random Forest - Mean CV score:\", np.mean(scores))\n",
    "\n",
    "# Train the classifier on the full training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Random Forest - Test accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "svm_clf = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "svm_scores = cross_val_score(svm_clf, X_train, y_train, cv=5)\n",
    "print(\"SVM - Cross-validation scores:\", svm_scores)\n",
    "print(\"SVM - Mean CV score:\", np.mean(svm_scores))\n",
    "\n",
    "# Train the classifier on the full training data\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = svm_clf.predict(X_test)\n",
    "print(\"SVM - Test accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the Logistic Regression classifier\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "log_reg_scores = cross_val_score(log_reg, X_train, y_train, cv=5)\n",
    "print(\"Logistic Regression - Cross-validation scores:\", log_reg_scores)\n",
    "print(\"Logistic Regression - Mean CV score:\", np.mean(log_reg_scores))\n",
    "\n",
    "# Train the classifier on the full training data\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "print(\"Logistic Regression - Test accuracy:\", accuracy_score(y_test, y_pred_log_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Initialize the Naive Bayes classifier\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "nb_scores = cross_val_score(nb_classifier, X_train, y_train, cv=5)\n",
    "print(\"Naive Bayes - Cross-validation scores:\", nb_scores)\n",
    "print(\"Naive Bayes - Mean CV score:\", np.mean(nb_scores))\n",
    "\n",
    "# Train the classifier on the full training data\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred_nb = nb_classifier.predict(X_test)\n",
    "print(\"Naive Bayes - Test accuracy:\", accuracy_score(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Initialize the MLP Classifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(256, 128), activation='relu', solver='adam', \n",
    "                    max_iter=500, random_state=42)\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "mlp_scores = cross_val_score(mlp, X_train, y_train, cv=5)\n",
    "print(\"MLP - Cross-validation scores:\", mlp_scores)\n",
    "print(\"MLP - Mean CV score:\", np.mean(mlp_scores))\n",
    "\n",
    "# Train the classifier on the full training data\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred_mlp = mlp.predict(X_test)\n",
    "print(\"MLP - Test accuracy:\", accuracy_score(y_test, y_pred_mlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Word2Vec\n",
    "sentences = [row.split() for row in df['review']]\n",
    "word2vec = Word2Vec(sentences, min_count=1)\n",
    "review_vectors = [] # Create a vector for each review by taking the mean of the vectors of its words\n",
    "for sentence in sentences:\n",
    "    vector_list = [word2vec.wv[word] for word in sentence if word in word2vec.wv.key_to_index]\n",
    "    review_vectors.append(np.mean(vector_list, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "labels = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    review_vectors, labels, test_size=0.2, random_state=42, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Initialize the classifier\n",
    "clf = RandomForestClassifier(random_state=22)\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "print(\"Random Forest - Cross-validation scores:\", scores)\n",
    "print(\"Random Forest - Mean CV score:\", np.mean(scores))\n",
    "\n",
    "# Train the classifier on the full training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Random Forest - Test accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "svm_clf = SVC()\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "svm_scores = cross_val_score(svm_clf, X_train, y_train, cv=5)\n",
    "print(\"SVM - Cross-validation scores:\", svm_scores)\n",
    "print(\"SVM - Mean CV score:\", np.mean(svm_scores))\n",
    "\n",
    "# Train the classifier on the full training data\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = svm_clf.predict(X_test)\n",
    "print(\"SVM - Test accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the Logistic Regression classifier\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "log_reg_scores = cross_val_score(log_reg, X_train, y_train, cv=5)\n",
    "print(\"Logistic Regression - Cross-validation scores:\", log_reg_scores)\n",
    "print(\"Logistic Regression - Mean CV score:\", np.mean(log_reg_scores))\n",
    "\n",
    "# Train the classifier on the full training data\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "print(\"Logistic Regression - Test accuracy:\", accuracy_score(y_test, y_pred_log_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Initialize the Naive Bayes classifier\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "nb_scores = cross_val_score(nb_classifier, X_train, y_train, cv=5)\n",
    "print(\"Naive Bayes - Cross-validation scores:\", nb_scores)\n",
    "print(\"Naive Bayes - Mean CV score:\", np.mean(nb_scores))\n",
    "\n",
    "# Train the classifier on the full training data\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred_nb = nb_classifier.predict(X_test)\n",
    "print(\"Naive Bayes - Test accuracy:\", accuracy_score(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Initialize the MLP Classifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(256, 128), activation='relu', solver='adam', \n",
    "                    max_iter=500, random_state=42)\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "mlp_scores = cross_val_score(mlp, X_train, y_train, cv=5)\n",
    "print(\"MLP - Cross-validation scores:\", mlp_scores)\n",
    "print(\"MLP - Mean CV score:\", np.mean(mlp_scores))\n",
    "\n",
    "# Train the classifier on the full training data\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred_mlp = mlp.predict(X_test)\n",
    "print(\"MLP - Test accuracy:\", accuracy_score(y_test, y_pred_mlp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
